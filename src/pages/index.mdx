---
layout: ../layouts/Layout.astro
title: "Accessible AI-Navigation for the Visually Impaired: State, UX & Directions"
description: "Enhancing Accessibility for Visually Impaired Students through AI-Powered Navigation at Academic Institutional Environments: The State of Systems, User Experiences, and Future Directions"
favicon: favicon.svg
thumbnail: screenshot-light.png
---

import Header from "../components/Header.astro";
import Video from "../components/Video.astro";
import HighlightedSection from "../components/HighlightedSection.astro";
import SmallCaps from "../components/SmallCaps.astro";
import Figure from "../components/Figure.astro";
import Image from "../components/Image.astro";
import TwoColumns from "../components/TwoColumns.astro";
import YouTubeVideo from "../components/YouTubeVideo.astro";
import LaTeX from "../components/LaTeX.astro";

import { ImageComparison } from "../components/ImageComparison.tsx";

import outside from "../assets/outside.mp4";
import transformer from "../assets/transformer.webp";
import Splat from "../components/Splat.tsx"
import dogsDiffc from "../assets/dogs-diffc.png"
import dogsTrue from "../assets/dogs-true.png"


import CodeBlock from "../components/CodeBlock.astro";
import Table from "../components/Table.astro";
export const components = {pre: CodeBlock, table: Table}

<Header
  title={frontmatter.title}
  authors={[
    {
      name: "Ehsanur Rahman Rhythm",
      url: "https://orcid.org/0000-0002-4641-508X",
      institution: "BRAC University & IIT, University of Dhaka",
      notes: ["1", "4"],
    },
    {
      name: "Rakibul Hasan",
      institution: "BRAC University & Northern University Bangladesh",
      notes: ["1", "2"],
    },
    {
      name: "Md Mahadi Hasan",
      institution: "BRAC University & Northern University Bangladesh",
      notes: ["1", "2"],
    },
    {
      name: "Labib Hasan Khan",
      institution: "BRAC University",
      notes: ["1"],
    },
    {
      name: "Md Sabbir Hossain",
      institution: "BRAC University",
      notes: ["1"],
    },
    {
      name: "Annajiat Alim Rasel",
      url: "https://orcid.org/0000-0003-0198-3734",
      institution: "BRAC University & Jahangirnagar University",
      notes: ["1", "3"],
    },
    {
      name: "Mohammad Zahidur Rahman",
      url: "https://orcid.org/0000-0002-0998-569X",
      institution: "Jahangirnagar University",
      notes: ["3"],
    },
  ]}
  conference="International Conference on Data Science, AI and Applications (ICDSAIA) "
  notes={[
    {
      symbol: "1",
      text: "Department of Computer Science and Engineering, School of Data and Sciences, BRAC University, Bangladesh",
    },
    {
      symbol: "2",
      text: "Department of Computer Science and Engineering, Northern University Bangladesh, Dhaka, Bangladesh",
    },
    {
      symbol: "3",
      text: "Department of Computer Science and Engineering, Jahangirnagar University, Bangladesh",
    },
    {
      symbol: "4",
      text: "Institute of Information Technology, University of Dhaka, Dhaka-1000, Bangladesh",
    },
  ]}
  />


<h2 id="appendix-a">Appendix A: Overview of Indoor Navigation Technologies</h2>

- **Bluetooth Low Energy (BLE) Beacons**: BLE beacons are small, inexpensive devices that send signals to smartphones, allowing for proximity-based location. By detecting signal strength, these systems can predict a user's location to within a few meters, making them appropriate for large-scale deployments in university settings [1].

- **Wi-Fi Positioning**: Wi-Fi positioning triangulates a user's location using signal levels from several access points. While frequently available, signal interference, common in busy campuses, can reduce its precision to 5-10 meters.

- **Ultra-Wideband (UWB)**: UWB measures radio wave travel time between devices for centimeter-accuracy location. Precision makes it ideal for complex navigation tasks, but needs specialized equipment [2].

- **Computer Vision**: Computer vision scans camera pictures to identify landmarks, signs, and barriers, delivering positional and contextual information. Blind users needing real-time environmental awareness will be helped from this.

- **Inertial Measurement Units (IMUs)**: IMUs with accelerometers and gyroscopes measure motion and orientation. When used with other technologies, dead reckoning can predict location changes, enhancing navigation continuity in signal-poor areas.

<h2 id="appendix-b">Appendix B: AI Techniques in Navigation Systems</h2>

- **Localization**: Machine learning systems, such neural networks, accurately forecast user locations using sensor data. Graph neural networks may achieve interior localization errors as low as 1.29 meters, demonstrating its potential for precise academic building placement.

- **Obstacle Detection**: Deep learning models, especially CNNs, excel in detecting barriers in video or sensor data. YOLO systems, adjusted for real-time obstacle identification, achieve accuracy rates surpassing 99.9% in controlled conditions. This is essential for safe navigation around dangers like sloping pillars or elevators.

- **Path Planning**: AI systems, such as reinforcement learning and A*, calculate ideal pathways while avoiding obstacles. Reinforcement learning may leverage real-time data to adjust to dynamic campus circumstances like crowded hallways.

- **Natural Language Processing (NLP)**: Large language models (LLMs) provide human-like navigation directions, improving system usability for blind individuals. According to research, 83.3% of users considered LLM-generated instructions accurate and easy to follow, making navigation aids more accessible [3].

<h2 id="appendix-c">Appendix C: User Experiences and Accessibility Insights</h2>

<p>AI-based navigation systems have improved in technical performance, achieving high accuracy in localization (3 cm with UWB, 1.29 meters with graph neural networks) and obstacle detection (95-97.3\% with deep learning models).  These technologies may be used in academic contexts, as shown by Johns Hopkins and University of Central Asia systems. Most studies use controlled or simulated settings, with little real-world assessment of blind students in various university settings like Bangladesh.</p>
<p>User-centric research show university navigation demands including identifying rooms and spotting impediments. Independent navigation requires head-level obstacle detection and interactive feedback, which existing systems typically lack. Commercial solutions like Navigine and wearable gadgets like NOA by biped.ai are useful, but universities need further proof.</p>
<p>Future research should focus university field investigations with blind students to measure usability and efficacy to fill these gaps.  An inclusive design using multimodal input (auditory, tactile, and haptic) can improve accessibility and user experience.  AI-based navigation systems can improve campus life for blind students by bridging technology advances and practical implementation, supporting institutional accessibility and inclusion goals.</p>


<h2 id="appendix-d">Appendix D: Advanced AI Techniques for Navigation Systems</h2>
<p>System dependability may be improved by advanced AI approaches in dynamic campus situations. Reinforcement learning lets systems adapt to shifting crowds or transitory impediments by learning from environmental interactions in real time. Through collaborative training without exposing sensitive data, federated learning may create models that generalize across campuses and adapt to diverse institution architectures. Systems can be developed and tested on campus digital twins to ensure robustness before implementation. Generative AI might anticipate crowd movements and adapt routes. Real-time object identification using deep learning can enhance obstacle avoidance, attaining up to 99.56\% accuracy in regulated situations. These methods should be combined to construct responsive, scalable navigation systems in future study.</p>

<h2 id="tables">Appendix E: Tables</h2>

| System Name | AI Technology | Localization Accuracy | Tested in University Settings |
| :--- | :--- | :--- | :--- |
| HoGNNLoc | Graph Neural Network | 1.29 m at 80% CDF | Yes (UJIIndoorLoc) |
| Autoencoder-based CNN | Convolutional Neural Network | 4.55 m mean error | Yes (UJIIndoorLoc) |
| UWB with DNN | Deep Neural Network | 3 cm mean absolute error | No |
| Wearable RGB-D System | Not specified | 0.88 m average error | Yes (university-like) |

<Figure>
  <span slot="caption">Table 1: AI-Based Localization Systems for Indoor Navigation</span>
</Figure>

| System Name | AI Technology | Detection Accuracy |
| :--- | :--- | :--- |
| AI-SenseVision | YOLOv3 | 83.44% mAP |
| Smart Assistive Framework | AlexNet | 99.56% validation accuracy |
| EchoSight | Deep Learning | 95% accuracy |
| Stair Detection | Deep Learning | 97.3% accuracy |

<Figure>
  <span slot="caption">Table 2: AI-Based Obstacle Detection Systems</span>
</Figure>

| System Name | Function | AI Technology | Accuracy | Tested in University Settings |
| :--- | :--- | :--- | :--- | :--- |
| Johns Hopkins System | Wayfinding & Obstacle Detection | AI for mapping and guidance | Not specified | Yes |
| Smart Assistive Navigation System | Wayfinding & Obstacle Detection | YOLOV8 for detection, navigation guidance | 91.7% detection accuracy | No |

<Figure>
  <span slot="caption">Table 3: Integrated AI-Based Navigation Systems</span>
</Figure>

<h2 id="bibtex-citation">BibTeX citation</h2>

Citation format will be updated when published.

<h2 id="references">References</h2>

[1] Campus Navigation System | University Indoor Navigation Solutions â€” navigine.com. https://navigine.com/industries/universities/, [Accessed 14-05-2025]

[2] Arslantas, Y. E., and Vala Jeyhani. "Indoor positioning: ultra-wideband." 2024.

[3] Dorbala, V. R., et al. "LLMs Generate Human-like Wayfinding Instructions for Indoor Navigation." 2024.