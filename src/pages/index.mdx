---
layout: ../layouts/Layout.astro
title: "Enhancing Accessibility for Visually Impaired Students through AI-Powered Navigation at Academic Institutional Environments: The State of Systems, User Experiences, and Future Directions"
description: Simple project page template for your research paper, built with Astro and Tailwind CSS
favicon: favicon.svg
thumbnail: screenshot-light.png
---

import Header from "../components/Header.astro";
import Video from "../components/Video.astro";
import HighlightedSection from "../components/HighlightedSection.astro";
import SmallCaps from "../components/SmallCaps.astro";
import Figure from "../components/Figure.astro";
import Image from "../components/Image.astro";
import TwoColumns from "../components/TwoColumns.astro";
import YouTubeVideo from "../components/YouTubeVideo.astro";
import LaTeX from "../components/LaTeX.astro";

import { ImageComparison } from "../components/ImageComparison.tsx";

import outside from "../assets/outside.mp4";
import transformer from "../assets/transformer.webp";
import Splat from "../components/Splat.tsx"
import dogsDiffc from "../assets/dogs-diffc.png"
import dogsTrue from "../assets/dogs-true.png"


import CodeBlock from "../components/CodeBlock.astro";
import Table from "../components/Table.astro";
export const components = {pre: CodeBlock, table: Table}

<Header
  title={frontmatter.title}
  authors={[
    {
      name: "Ehsanur Rahman Rhythm",
      url: "https://orcid.org/0000-0002-4641-508X",
      institution: "BRAC University & IIT, University of Dhaka",
      notes: ["1", "4"],
    },
    {
      name: "Rakibul Hasan",
      institution: "BRAC University & Northern University Bangladesh",
      notes: ["1", "2"],
    },
    {
      name: "Md Mahadi Hasan",
      institution: "BRAC University & Northern University Bangladesh",
      notes: ["1", "2"],
    },
    {
      name: "Labib Hasan Khan",
      institution: "BRAC University",
      notes: ["1"],
    },
    {
      name: "Md Sabbir Hossain",
      institution: "BRAC University",
      notes: ["1"],
    },
    {
      name: "Annajiat Alim Rasel",
      url: "https://orcid.org/0000-0003-0198-3734",
      institution: "BRAC University & Jahangirnagar University",
      notes: ["1", "3"],
    },
    {
      name: "Mohammad Zahidur Rahman",
      url: "https://orcid.org/0000-0002-0998-569X",
      institution: "Jahangirnagar University",
      notes: ["3"],
    },
  ]}
  conference="International Conference on Data Science, AI and Applications (ICDSAIA) "
  notes={[
    {
      symbol: "1",
      text: "Department of Computer Science and Engineering, School of Data and Sciences, BRAC University, Bangladesh",
    },
    {
      symbol: "2",
      text: "Department of Computer Science and Engineering, Northern University Bangladesh, Dhaka, Bangladesh",
    },
    {
      symbol: "3",
      text: "Department of Computer Science and Engineering, Jahangirnagar University, Bangladesh",
    },
    {
      symbol: "4",
      text: "Institute of Information Technology, University of Dhaka, Dhaka-1000, Bangladesh",
    },
  ]}
  />

<HighlightedSection>
Abstract will be added later.
</HighlightedSection>

<h2 id="appendix-a">Appendix A: Overview of Indoor Navigation Technologies</h2>

- **Bluetooth Low Energy (BLE) Beacons**: BLE beacons are small, inexpensive devices that send signals to smartphones, allowing for proximity-based location. By detecting signal strength, these systems can predict a user's location to within a few meters, making them appropriate for large-scale deployments in university settings [1].

- **Wi-Fi Positioning**: Wi-Fi positioning triangulates a user's location using signal levels from several access points. While frequently available, signal interference, common in busy campuses, can reduce its precision to 5-10 meters.

- **Ultra-Wideband (UWB)**: UWB measures radio wave travel time between devices for centimeter-accuracy location. Precision makes it ideal for complex navigation tasks, but needs specialized equipment [2].

- **Computer Vision**: Computer vision scans camera pictures to identify landmarks, signs, and barriers, delivering positional and contextual information. Blind users needing real-time environmental awareness will be helped from this.

- **Inertial Measurement Units (IMUs)**: IMUs with accelerometers and gyroscopes measure motion and orientation. When used with other technologies, dead reckoning can predict location changes, enhancing navigation continuity in signal-poor areas.

<h2 id="appendix-b">Appendix B: AI Techniques in Navigation Systems</h2>

- **Localization**: Machine learning systems, such neural networks, accurately forecast user locations using sensor data. Graph neural networks may achieve interior localization errors as low as 1.29 meters, demonstrating its potential for precise academic building placement.

- **Obstacle Detection**: Deep learning models, especially CNNs, excel in detecting barriers in video or sensor data. YOLO systems, adjusted for real-time obstacle identification, achieve accuracy rates surpassing 99.9% in controlled conditions. This is essential for safe navigation around dangers like sloping pillars or elevators.

- **Path Planning**: AI systems, such as reinforcement learning and A*, calculate ideal pathways while avoiding obstacles. Reinforcement learning may leverage real-time data to adjust to dynamic campus circumstances like crowded hallways.

- **Natural Language Processing (NLP)**: Large language models (LLMs) provide human-like navigation directions, improving system usability for blind individuals. According to research, 83.3% of users considered LLM-generated instructions accurate and easy to follow, making navigation aids more accessible [3].



<h2 id="figures">Figures</h2>

Use the figure component to display images, videos, equations, or any other element, with an optional caption.

<Figure>
  <Image slot="figure" source={transformer} altText="Diagram of the transformer deep learning architecture." />
  <span slot="caption">Diagram of the transformer deep learning architecture.</span>
</Figure>

<h2 id="image-comparison-slider">Image comparison slider</h2>

An interactive, accessible slider component with keyboard navigation.
<Figure>
  <ImageComparison slot="figure" client:load imageUrlOne={dogsDiffc.src} imageUrlTwo={dogsTrue.src} altTextOne="Photo of two dogs running side-by-side in shallow water, lossily compressed using the DiffC algorithm" altTextTwo="Original photo of two dogs running side-by-side in shallow water" />
  <span slot="caption">A photo of two dogs running side-by-side in shallow water, lossily compressed using the <a href="https://jeremyiv.github.io/diffc-project-page/">DiffC algorithm</a>.</span>
</Figure>

<h2 id="two-columns">Two columns</h2>

Use the two columns component to display two columns of content. In this example, the first column contains a figure with a YouTube video and the second column contains a figure with a custom [React](https://react.dev/) component. By default, they display side by side, but if the screen is narrow enough (for example, on mobile), they're arranged vertically.

<TwoColumns>
  <Figure slot="left">
    <YouTubeVideo slot="figure" videoId="wjZofJX0v4M" />
    <span slot="caption">Take a look at this YouTube video.</span>
  </Figure>
  <Figure slot="right">
    <Splat slot="figure" client:idle />
    <span slot="caption">Now look at this <a href="https://en.wikipedia.org/wiki/Gaussian_splatting">Gaussian splat</a>, rendered with a React component.</span>
  </Figure>
</TwoColumns>

<h2 id="heading-levels">Heading levels</h2>

Use headings to divide your content into sections.

<h3 id="heading-3">Heading 3</h3>

Go down a level to heading 3...

<h4 id="heading-4">Heading 4</h4>

...and down again to heading 4.

<h2 id="latex">LaTeX</h2>

You can also add LaTeX formulas, rendered during the build process using [KaTeX](https://katex.org/) so they're quick to load for visitors of your project page. You can write them inline, like this: <LaTeX inline formula="a^2 + b^2 = c^2" />. Or, you can write them as a block:

<LaTeX formula="\int_a^b f(x) dx" />

<h2 id="tables">Tables</h2>

You can add simple tables using [GitHub Flavored Markdown syntax](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/organizing-information-with-tables):

| Model | Accuracy | F1 score | Training time (hours) |
| :--- | :---: | :---: | :---: |
| BERT-base | 0.89 | 0.87 | 4.5 |
| RoBERTa-large | 0.92 | 0.91 | 7.2 |
| DistilBERT | 0.86 | 0.84 | 2.1 |
| XLNet | 0.90 | 0.89 | 6.8 |

<h2 id="bibtex-citation">BibTeX citation</h2>

Citation format will be updated when published.

<h2 id="references">References</h2>

[1] Campus Navigation System | University Indoor Navigation Solutions â€” navigine.com. https://navigine.com/industries/universities/, [Accessed 14-05-2025]

[2] Arslantas, Y. E., and Vala Jeyhani. "Indoor positioning: ultra-wideband." 2024.

[3] Dorbala, V. R., et al. "LLMs Generate Human-like Wayfinding Instructions for Indoor Navigation." 2024.